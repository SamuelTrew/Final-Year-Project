\section{Motivation}
The use of Machine Learning (ML) to enhance user experiences, to provide fantastic tools, or to be able to make accurate predictions all require large amounts of data --- this is normally collected by a single body/organisation.
This has its limitations; there are cases where not enough data can be collected by any one group of people. 
An example of this is with medical data.
\\ \\
Medical data is typically well-protected, with many regulations in place to prevent its misuse \cite{nhs_digital_data}.  
This is due to the sensitive nature of the data, that pertains to an individual's state of health and other private information.
Directly exposing such information to researchers is undesirable. 
While these protections (in the form of legislation such as the General Data Protection Regulation (GDPR) \cite{gdpr} or Health Insurance Portability and Accountability Act (HIPAA) \cite{hipaa}) are beneficial to user confidentiality, this poses a problem to researchers. 
This limits their ability to apply data-intensive ML procedures in the medical sector.\\

Typical methods of training ML models would not work as the personal data should not leave the hospitals or the devices of the users. 
This is where Federated Learning (FL) \cite{federated_comic} comes in. 
FL is where each client involved in the procedure trains an agreed upon model on their own data. 
Instead of sharing the data with anyone else, they now share the model they trained with a central server. 
This server then combines all of the models from all of the clients together to form one unified model. 
This is then distributed back out to the clients and the model is further trained on the data. 
The process is repeated until the model converges.
\\ \\
However, this style of collaborative learning can be exploited by malicious or faulty clients \textbf{sending bad updates} to the server, interfering with the global model. 
There are already several methods for defending this to allow robust aggregation, but with the varying styles and complexities of current attacks, they can be shown to be insufficient.
\\ \\
There is also the case of clients trying to \textbf{steal the model} without contributing and this kind of unique attack poses to be a formidable foe against current aggregators.
Investigating, enhancing and creating a robust aggregator to be able to handle all of these attacks is a tricky problem, but one that will be detailed throughout this report.


\section{Objectives}
The main focus of this project is to implement and evaluate robust aggregation methods for FL.
In our work, we will be using well-known datasets such as MNIST, that are good for covering the variety of attacks we are considering.
However, other forms of ML (e.g. LSTMs) might be susceptible to different types of attacks and it should be noted that these won't be covered.
\\ \\
The initial experiments will be done using MNIST \cite{mnist} digit classification, as it serves a good baseline for initial investigation.  This is to gauge the performance of the robust aggregation algorithms when applied to such common datasets.
Then, we will conduct an evaluation of the different strategies, and determine the driving characteristics behind their performance. This will provide insight into what helps tackle the issues faced by FL.
\\ \\
We will then lead into creating our own robust aggregation strategy, one that is more capable of handling a large variety and combinations of attacks in a robust manner.
The aim would be to end up with a State of the Art (SotA) algorithm that outperforms the other solutions.
\\ \\
In the future, we would like to be able to do some further investigation into the medical realm. This is to evaluate the performance of our aggregator on a real-world dataset.
This might be harder to achieve in practice due to the sensitive nature of the data. A competition dataset that is publicly available might prove to be the better option.




\section{Challenges}
\begin{enumerate}
    \item \textbf{Tuning hyper-parameters:} 
    The robust aggregation methods all have their own set of unique hyper-parameters that need fine-tuning. This adds to the complexity of running our experiments, as it is difficult to obtain a definitive, optimal parameterisation of each method.
        
    \item \textbf{Type of attacks:} 
    Identifying viable and representative real-world attacks could prove complicated. 
    There are a wide range of attacks and so there might not be time to do full-scale testing on all of them.
    Instead, this project will focus on some on the current attack strategies to a deeper, and not broader, extent.

    \item \textbf{Number of configurations:}  
    Every possible attack, variations in the structure of the attack, and variation in the number of clients requires a complete re-training and testing of the model. 
    This is hugely time consuming if not planned well, given the limited duration of this project.
    
    \item \textbf{Computational resources:}
    The Machine Learning and distributed nature of this project makes it resource intensive. 
    Increasing the number of users that we test with or having a more complex Deep Learning network all contributes to this.
    Having a more powerful system at my disposal would help make it more feasible to get more done in this time-frame.
\end{enumerate}